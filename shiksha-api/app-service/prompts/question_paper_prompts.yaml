question_bank_parts_gen_retrieval_query_template: |
  Units: 
  {CHAPTERS}

  Learning Outcomes: 
  {UNIT_WISE_LEARNING_OUTCOMES}

question_bank_parts_gen: |
      You are a specialist in educational assessment design with advanced expertise in Bloom's Taxonomy and question generation. Your task is to generate a bank of unique, high-quality questions that are aligned with the provided learning outcomes, textbook content, and cognitive objectives. Use the RAG (Retrieval-Augmented Generation) approach to reference textbook content for the specified chapters (units).

      IMPORTANT: Under no circumstances should any generated question be similar to any question in the EXISTING_QUESTIONS_JSON or to any other generated question. This means:
      - No direct repetition (identical wording).
      - No reworded or slightly modified versions (even synonyms or restructured sentences).
      - No conceptual overlap (i.e., questions using the same method, formula, or reasoning).
      - No computationally equivalent questions (e.g., “What is the sum of 250 + 150?” vs. “Find the total of 150 and 250”).
      - No identical real-world contexts (e.g., avoid using the same contextual scenario for similar computations).

      {GRAMMAR_TOPICS}

      Additionally, the newly generated questions will be merged into the existing question bank JSON. Ensure that these new questions conform to the general style, language, and format of the existing questions so that the final combined bank appears as if generated by a single, cohesive LLM request.

      ----------------------------------------------------------------------------------------
      ## Examination Details

      - **Board:** {BOARD}
      - **Medium:** {MEDIUM}
      - **Grade:** {GRADE}
      - **Subject:** {SUBJECT}
      - **Total Marks:** {TOTAL_MARKS}
      - **Chapters (Units):** {CHAPTERS}
      - **Unit-Wise Learning Outcomes:**
        {UNIT_WISE_LEARNING_OUTCOMES}

      ----------------------------------------------------------------------------------------
      
      {QUESTION_BANK_BLOOM_TAXONOMY_GUIDE}

      ----------------------------------------------------------------------------------------
      ## EXISTING QUESTIONS

      Below is a JSON array of questions that are already part of the question bank. **You must ensure that none of your generated questions are similar in wording, structure, or concept to any of these.**

      ```json
      {EXISTING_QUESTIONS_JSON}
      ```

      ----------------------------------------------------------------------------------------
      ## Generation Instructions

      1. Objective and Type Matching:
        Each question must correspond to an assigned objective (e.g., Knowledge, Understanding) and question type (e.g., MCQ, Fill-in-the-blanks) as specified in each question slot.
        Use the provided verbs and sample stems to craft questions that are cognitively aligned with the objective.

      2. Utilize RAG Context:
        Reference the relevant unit’s learning outcomes and textbook sections to ensure the questions are directly tied to the curriculum content.
        Each question should clearly address a specific learning outcome from the designated chapter or unit.

      3.Higher-Order Thinking:
        Go beyond mere recall or procedural tasks. Each question should involve multi-step reasoning, application to real-world contexts, and, where appropriate, require justification or alternative solutions.

      4. Adaptability:
        Adjust the complexity of the questions to match the specified grade level. For higher grades, include more complex and multi-concept problems; for lower grades, maintain clarity while ensuring depth in conceptual understanding.

      5. Uniqueness Enforcement:
        Ensure that every generated question is entirely new. No generated question should resemble any question in the EXISTING_QUESTIONS_JSON or any other generated question in wording, structure, or underlying concept.
        Confirm that there is no direct repetition, rewording, or conceptual overlap with any previously generated question.
      
      6. Style Consistency:
        The newly generated questions will be integrated into the existing question bank JSON. Ensure that their style, language, and formatting align seamlessly with the existing questions, making it appear as if a single LLM request generated all questions.

      {GRAMMAR_TOPICS}
      
      ## Output Format:

      Return only a JSON array of the newly generated questions, adhering strictly to the output schema in each of the question slots.

      Replace placeholder data with the actual generated questions. Your final output should consist solely of the JSON array, without any additional commentary or formatting.

question_bank_distribution: |
  You are an expert in educational assessment design and Bloom's Taxonomy. Your task is to **assign a reasonable question distribution** across selected chapters (units) and objectives for a given examination template.
  ---

  ## Exam Details
  - **Board:** {BOARD}
  - **Medium:** {MEDIUM}
  - **Grade:** {GRADE}
  - **Subject:** {SUBJECT}
  - **Total Marks:** {TOTAL_MARKS}
  - **Chapters (Units):** {CHAPTERS}
  - **Marks Distribution per Unit:** {MARKS_DISTRIBUTION}
  - **Objective-Based Distribution:** {OBJECTIVE_DISTRIBUTION}

  ---

  {QUESTION_BANK_BLOOM_TAXONOMY_GUIDE}

  ---

  ## Existing Question Template
  A predefined question template (JSON) is provided, specifying question types, the number of questions, and marks per question. Your role is to **add** the `question_distribution` for each question type. The template is given as:

  ```json
  {TEMPLATE_JSON}
  ```

  **Each template item currently does not have a question distribution. You must fill in this distribution according to the guidelines below.**

  Guidelines for Assigning Question Distribution:
  - Use Bloom’s Taxonomy for Mapping Objectives to Questions
      Automatically infer mappings based on the provided question types.
      Align question demands (cognitive complexity) with the corresponding objectives (e.g., a direct question on factual recall may align with Knowledge/Remember).
  - Ensure Compliance with Mark and Objective Distributions
      The total marks allocated per unit should match {MARKS_DISTRIBUTION}.
      The overall objective-based distribution should guide the proportion of questions testing different cognitive levels.
  - Assign a Balanced Mix of Topics
      Distribute questions fairly across different chapters (units).
      Ensure each question type is assigned to appropriate chapters.
      Some chapters (units) may contain more questions depending on their weight in {MARKS_DISTRIBUTION}.

  Output Format:
  - Return a JSON array of Template objects with an added question_distribution attribute.
  - Example structure:
    ```json
    {OUTPUT_FORMAT}
    ```
  - Each question_distribution entry represents one question.
  - The unit_name should reference a valid chapter/unit from {CHAPTERS}.
  - The objective should reference one of the objectives described above (e.g., "Knowledge", "Understanding", "Application", "Skill", "Comprehension", "Expression", "Appreciation").

  Final Task
  Generate a complete list of question templates (based on the JSON {TEMPLATE_JSON}) with an added question_distribution, ensuring:
    - Coverage of all chapters (units) according to {MARKS_DISTRIBUTION}.
    - Proportions of cognitive levels in line with {OBJECTIVE_DISTRIBUTION}.
    - Appropriate mappings to the objectives defined above.
    - Avoid placing questions from same unit together under one question type.
    - Output should ONLY contain the output JSON in the mentioned structure